
# Predictive model and Regressors:
* Predictive modeling is the problem of developing a model using historical data to make a prediction on new data where we do not have the answer.
* Predictive modeling can be described as the mathematical problem of approximating a mapping function (f) from input variables (X) to output variables (y). This is called the problem of function approximation.
* The job of the modeling algorithm is to find the best mapping function we can given the time and resources available.

		Classification is the task of predicting a discrete class label.
		Regression is the task of predicting a continuous quantity.

* Fundamentally, classification is about predicting a label and regression is about predicting a quantity.

[Read more about this ](https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/)

* 10 regressors we will discuss in this topic:

		1.DecisionTreeRegressor
		2.ElasticNet
		3.GradientBoostingRegressor
		4.KernelRidge
		5.Lasso
		6.LinearRegression
		7.RandomForestRegressor
		8.Ridge
		9.SGDRegressor
		10.System Identification
# Scoring : Loss functions use in regressing
* Input: arrays of data specified by an ordered sequence of fields(the acutal and predicted fields)
* Output: raw_values: regressions scores or errors between each field in fields_a and field_b
		
	1. Explained variance score (EVS) when mean residual = 0 it is R2
	2. Mean absolute error score (MAE)
	3. Mean squared error (MSE)
	4. R2 score (R2)
## 1. Explained variance score:Best possible score is 1.0, lower values are worse. It explains how far observed values differ from the average of predicted values
* Explaned variance score in python: L(y_true,y_pred)= EVS = 1-np.cov(np.array(y_true)-np.array(y_pred))/np.cov(y_true)
* When the mean residual = 0. Explained variance score is equal with R2

Example on sklearn:

![](image./sklearn_EVS.png)

	Residual = Observed value – predicted value
	e = y – ŷ
	
	Mean residual= (11.5-12.5)/4 =-0.25 when y_pred = [2.5, 0.0, 2, 8] 
	Mean residual= 0 when y_pred=[2.5, 0.0, 2, 7]
	
[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/ScoreCommand#Regression_scoring)

[Read it on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score)
### Syntax on Splunk:
![](image./explained_var_score_syntax.png)

Param:
* multioutput: str in [‘raw_values’, ‘uniform_average’, ‘variance_weighted’]. Defines weights used to average scores.

	1. ‘raw_values’ : Returns a full set of scores in case of multioutput input.
	2. ‘uniform_average’ : Scores of all outputs are averaged with uniform weight.
	3. ‘variance_weighted’ : Scores of all outputs are averaged, weighted by the variances 
	of each individual output.

### Example on power_plant dataset with RFR algr
	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| fit DecisionTreeRegressor Energy_Output max_features=auto min_samples_split=2 
	random_state=1234 splitter=best from * into my_DTR as energy_DTR_default
	| fit DecisionTreeRegressor Energy_Output max_features=2 min_samples_split=2 
	random_state=1234 splitter=best from * into my_DTR_2 as energy_DTR_2
	| score explained_variance_score Energy_Output against energy_DTR_default energy_DTR_2 
	multioutput=raw_values

![](image./explained_var_score_fit.png)

	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| apply my_DTR as pred_energy_default
	| apply my_DTR_2 as pred_energy
	| score explained_variance_score Energy_Output, Energy_Output against 
	pred_energy_default,pred_energy

![](image./explained_var_score_apply.png)

## 2. Mean absolute error score - MAE :
![](image./MAE.png)

Mean Absolute Error (MAE): MAE measures the average magnitude of the errors in a set of predictions, without considering their direction.

MAE is not sensitive towards outliers and given several examples with the same input feature values, the optimal prediction will be their median target value. This should be compared with Mean squared error (MSE), where the optimal prediction is the mean.

Use MAE when you are doing regression and don’t want outliers to play a big role. It can also be useful if you know that your distribution is multimodal, and it’s desirable to have predictions at one of the modes, rather than at the mean of them.

[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/ScoreCommand#Mean_absolute_error_score)

[Read it on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error)
### Syntax on Splunk:
![](image./mean_absolute_error_syntax.png)

Param:
* multioutput: str in [‘raw_values’, ‘uniform_average’]. Defines aggregating of multiple output values

		1.‘raw_values’ : Returns a full set of scores in case of multioutput input.
		2.‘uniform_average’ : Scores of all outputs are averaged with uniform weight.

### Example on power_plant dataset with RFR algr
	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| fit DecisionTreeRegressor Energy_Output max_features=auto min_samples_split=2 
	random_state=1234 splitter=best from * into my_DTR as energy_DTR_default
	| fit DecisionTreeRegressor Energy_Output max_features=2 min_samples_split=2 
	random_state=1234 splitter=best from * into my_DTR_2 as energy_DTR_2
	| score mean_absolute_error Energy_Output against energy_DTR_default energy_DTR_2 multioutput=uniform_average

![](image./mean_absolute_error_fit.png)

## 3. Mean absolute error score - MAE :
![](image./MSE.png)

Mean squared error (MSE): Like MAE, treats deviations in either direction the same way. MSE diff to MAE is that MSE will tend to punish large errors more because it squares all the errors.

Minimizing MSE is equivalent of maximizing the likelihood of the data under the assumption that the target comes from a normal distribution, conditioned on the input.

MSE is sensitive towards outliers and given several examples with the same input feature values, the optimal prediction is the median. Thus, MSE is good to use if you believe that your target data, conditioned on the input, is normally distributed around a mean value, and when it's important to penalize outlier extra much. 

Use MSE when doing regression, believing that your target, conditioned on the input, is normally distributed, and want large errors to be significantly more penalized than small ones.

[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/ScoreCommand#Mean_squared_error)

[Read it on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error)
### Syntax on Splunk:
![](image./MSE_syntax.png)

Param:
* multioutput: str in [‘raw_values’, ‘uniform_average’]. Defines aggregating of multiple output values

		1.‘raw_values’ : Returns a full set of scores in case of multioutput input.
		2.‘uniform_average’ : Scores of all outputs are averaged with uniform weight.

### Example on power_plant dataset with RFR algr
	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| fit DecisionTreeRegressor Energy_Output max_features=auto min_samples_split=2 
	random_state=1234 splitter=best from * into my_DTR as energy_DTR_default
	| fit DecisionTreeRegressor Energy_Output max_features=2 min_samples_split=2 
	random_state=1234 splitter=best from * into my_DTR_2 as energy_DTR_2
	| score mean_squared_error Energy_Output against energy_DTR_default energy_DTR_2 multioutput=uniform_average

![](image./MSE_fit.png)

## 4. R2 score (R2): varies between 0 and 100%
![](image./R2.png)

wiki:  ” … is the proportion of the variance in the dependent variable that is predictable from the independent variable(s).”

Other def, total variance explained by model / total variance.

If it is 100%: the two variables are perfectly correlated, with no variance at all.

A low value would show a low level of correlation, meaning a regression model that is not valid.

[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/ScoreCommand#R2_score)

[Read it on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score)
### Syntax on Splunk:
![](image./R2_syntax.png)

Param:
* multioutput: str in [‘raw_values’, ‘uniform_average’ 'variance_weighted']. Defines aggregating of multiple output values

		‘raw_values’ : Returns a full set of scores in case of multioutput input.
		‘uniform_average’ : Scores of all outputs are averaged with uniform weight.
		'variance_weighted':scores of all outputs, averaged with weights of each individual output's variance.

### Example on power_plant dataset with RFR algr
	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| fit DecisionTreeRegressor Energy_Output max_features=auto min_samples_split=2 
	random_state=1234 splitter=best from * into my_DTR as energy_DTR_default
	| fit DecisionTreeRegressor Energy_Output max_features=2 min_samples_split=2 
	random_state=1234 splitter=best from * into my_DTR_2 as energy_DTR_2
	| score r2_score Energy_Output against energy_DTR_default energy_DTR_2 multioutput=uniform_average

![](image./R2_fit.png)

# 1.DecisionTreeRegressor
[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/Algorithms#DecisionTreeRegressor)

[Read it on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)

Input: historical data. Output: function

![](image./DTregressor.png)

![](image./mse.png)

## Syntax on Splunk

![](image./DTR_syntax.png)

## Example: power_plant dataset with explained_variance_score method
	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| fit DecisionTreeRegressor Energy_Output max_features=auto min_samples_split=2 
	random_state=1234 splitter=best from * into my_DTR as energy_DTR_default
	| fit DecisionTreeRegressor Energy_Output max_features=2 min_samples_split=2 
	random_state=1234 splitter=best from * into my_DTR_2 as energy_DTR_2
	| score explained_variance_score Energy_Output against energy_DTR_default energy_DTR_2 
	multioutput=raw_values


![](image./explained_var_score_fit.png)

	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| apply my_DTR as pred_energy_default
	| apply my_DTR_2 as pred_energy
	| score explained_variance_score Energy_Output, Energy_Output against 
	pred_energy_default,pred_energy

![](image./explained_var_score_apply.png)

	|summary my_DTR
# 2. Linear Regression:
Ordinary least squares OLS attempts to minimize the sum of error squared. The equation for this model is referred to as the cost function and is a way to find the optimal error (the dif between the actual data point and its predicted value) by minimizing and measuring it.

![](image./LR.png)

[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/Algorithms#LinearRegression)
## Syntax on Splunk
![](image./LR_syntax.png)
## Example: power_plant dataset 
	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| fit LinearRegression Energy_Output from * into my_LR as energy_LR fit_intercept=True normalize=True
	| score r2_score Energy_Output against energy_LR multioutput=raw_values

![](image./LR_fit.png)

	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| apply my_LR as pred_energy_LR
	| score r2_score Energy_Output against pred_energy_LR multioutput=raw_values

![](image./LR_apply.png)
# 3.Ridge regression(L2): OLS + lamda * the slope^2 
One situation is the data showing multi-collinearity, this is when predictor variables are correlated to each other and to the response variable. 

To produce a more accurate model of complex data we can add a penalty term to the OLS equation. A penalty adds a bias towards certain values. These are known as L1 regularization(Lasso regression) and L2 regularization(ridge regression).

![](image./biasvariance.png)

Ridge regression has more bias than OLS. Thanks to a small bias, it had a significant drop in variance

![](image./L1L2.png)

* Ridge regression can only shrink the slop asymptotically close to 0. Ridge regression do litter better than Lasso regression in models that most variable are usefull.

[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/Algorithms#Ridge)
## Syntax on Splunk
![](image./L2_syntax.png)
## Example: power_plant dataset with explained_variance_score method
	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| fit Ridge Energy_Output from * into my_L2 as energy_L2 fit_intercept=True normalize=True alpha=0.5
	| score r2_score Energy_Output against energy_L1 multioutput=raw_values

![](image./L2_fit.png)
![](image./L2_summary.png)

	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| apply my_L2 as pred_energy_L2
	| score r2_score Energy_Output against pred_energy_L2 multioutput=raw_values

![](image./L2_apply.png)

# 4.Lasso regression(L1): OLS +lamda x |the slope| 
![](image./L1L2.png)
* Lasso regression can shrink the slope all the way to 0. when it is 0, Lasso regression is OLS. Thus, it can excule useless variables from the equations, it is a litte better than Ridge regression at reducing the Variance in models that contain a lot of useless variables.

[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/Algorithms#Lasso)
## Syntax on Splunk
![](image./L1_syntax.png)
## Example: power_plant dataset
	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| fit Lasso Energy_Output from * into my_L1 as energy_L1 fit_intercept=True normalize=True alpha=0
	| score r2_score Energy_Output against energy_L1 multioutput=raw_values

![](image./L1_fit.png)

	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| apply my_L1 as pred_energy_L1
	| score r2_score Energy_Output against pred_energy_L1 multioutput=raw_values

![](image./L1_apply.png)
# 5.ElasticNet
[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/Algorithms#ElasticNet)

[Read it on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)

Lasso regression works best in model that has a lot of useless varbles. Ridge regression works beat in model that has all usefull variables. When we know all our variables, we can decieded Lasso or Ridge. How about too many variables to know everything about? You use ElasticNet

![](image./EN.png)

		EN equation = lamda1 and lamda2 are greater than 0. 
		Lamda1 =Lamda2 =0 : it is OLS
		Lamda1>0; Lamda2 =0 : It is Lasso and vice-versa
## Syntax on Splunk

![](image./EN_syntax.png)

## Example: power_plant dataset 
	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| fit ElasticNet Energy_Output from * into my_EN as energy_EN fit_intercept=True normalize=True alpha=1.0 l1_ratio=0.5
	| score r2_score Energy_Output against energy_EN multioutput=raw_values

	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| apply my_EN as pred_energy_EN
	| score r2_score Energy_Output against pred_energy_EN multioutput=raw_values
	
# 6. GradientBoostingRegressor
Gardient Boosting regressor use an ensemble of decision trees to predict a target label.

[read about Gardient Bososting regressor tree](https://towardsdatascience.com/machine-learning-part-18-boosting-algorithms-gradient-boosting-in-python-ef5ae6965be4)

[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/Algorithms#GradientBoostingRegressor)

[Read it on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)
## Syntax on Splunk
![](image./GB_syntax.png)
Param:

		loss=<ls|lad|huber|quantile> : loss function to be optimized. 
		‘ls’ refers to least squares regression. 
		‘lad’ (least absolute deviation) is a highly robust loss function solely 
		based on order information of the input variables. 
		‘huber’ is a combination of the two. 
		‘quantile’ allows quantile regression (use alpha to specify the quantile).

## Example: power_plant dataset 
	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| fit GradientBoostingRegressor Energy_Output from * into my_GB as energy_GB 
	loss='ls' max_features=None learning_rate=0.1 min_weight_fraction_leaf=0.0 alpha=0.9 subsample=1.0 n_estimators=100 max_depth=3 min_samples_split=2 min_samples_leaf=1 random_state=1234
	| score r2_score Energy_Output against energy_GB multioutput=raw_values

![](image./GB_fit.png)

	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| apply my_GB as pred_energy_GB
	| score r2_score Energy_Output against pred_energy_GB multioutput=raw_values

![](image./GB_apply.png)

	|summary my_GB
![](image./GB_summary.png)

# 7. Kernel Ridge
Kernel ridge regression (KRR) combines ridge regression (linear least squares with l2-norm regularization) with the kernel trick.

[Kernel ridge regression math ](https://stat.fandom.com/wiki/Kernel_Ridge_Regression)
[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/Algorithms#KernelRidge)
## Syntax on Splunk
![](image./KR_syntax.png)
## Example: power_plant dataset 
	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| fit KernelRidge Energy_Output from * into my_KR as energy_KR 
	| score r2_score Energy_Output against energy_KR multioutput=raw_values

	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| apply my_KR as pred_energy_KR
	| score r2_score Energy_Output against pred_energy_KR multioutput=raw_values

![](image./KR.png)

# 8. RandomForestRegressor
A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default).

[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/Algorithms#RandomForestRegressor)

[Read it on Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)
## Syntax on Splunk
![](image./RFR_syntax.png)
## Example: housing dataset 
	| inputlookup housing.csv
	| sample partitions=506 seed=1234
	| search partition_number <= 400
	| fit RandomForestRegressor median_house_value from * into my_RF as housing_RF n_estimators=100 random_state=1234 max_features='auto'
	| score r2_score median_house_value against housing_RF multioutput=raw_values

![](image./RFR_fit.png)

	| inputlookup housing.csv
	| sample partitions=506 seed=1234
	| search partition_number > 400
	| apply my_RF as pred_housing_RF
	| score r2_score median_house_value against pred_housing_RF multioutput=raw_values

![](image./RFR_apply.png)

# 9. SGDRegressor
Gardient descent randomly selects a value as a minimal or optimal then keep changing the value in an iterative manner and the end, it gives a value that is actually very close to minima/maxima.

![](image./SGDR1.png)

If nos of data point(n) in data set very large then each iteration becomes very costly as in each iteration to compute grad of loss function we go through each data points. If nos of data points are like 10mil data points then that will require a lot of computing power and time too hence become costly.

![](image./SGDR2.png)

## So the solution to this is: Stochastic gradient descent also know as SGD:
Everything is the same as Gradient descent but only different is instead of taking n points to compute grad of loss function it randomly selects k sample from n data points in each iteration and computes grad of the loss function with that k data points in each iteration.

[Read more about it](https://medium.com/@rumankhan1/understanding-optimization-in-ml-with-gradient-descent-implement-sgd-regressor-from-scratch-4e11dac74c9)

[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/Algorithms#SGDRegressor)
## Syntax on Splunk
![](image./SGDR_syntax.png)
## Example: power_plant dataset 
	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| fit SGDRegressor Energy_Output from * into mySGD_default as energy_SGD
	partial_fit=false fit_intercept=true random_state=1234 n_iter=5 l1_ratio=0.15
	alpha=0.0001 eta0=0.01 power_t=0.25 penalty=l2 learning_rate=invscaling
	| score r2_score Energy_Output against energy_SGD multioutput=raw_values

![](image./SGDR_fit.png)

	| inputlookup power_plant.csv
	| sample partitions=9569 seed=1234
	| search partition_number <= 8000
	| apply mySGD_default as pred_energy_SGD
	| score r2_score Energy_Output against pred_energy_SGD multioutput=raw_values

![](image./SGDR_apply.png)

# 10. System Identification
Use the System Identification algorithm to model both non-linear and linear relationships. In a typical use case you predict a number of target fields from their past values as well as from the past and current values of other feature fields. The System Identification algorithm is powered by a multi-layered, fully-connected neural network. System Identification supports incremental fit.

[Read it on Splunk MLTK](https://docs.splunk.com/Documentation/MLApp/5.1.0/User/Algorithms#System_Identification)
## Syntax on Splunk
![](image./Si_syntax.png)
## Example: app_usage dataset Need \_time fields
The following example uses a fully-connected neural network with three hidden layers, each with a layer size of 64. The total number of layers in the neural network is five and comprised of one input layer, three hidden layers, and one output layer.

	| inputlookup app_usage.csv
	| fit SystemIdentification Expenses from HR1 HR2 ERP dynamics=3-1-2-3 
	layers=64-64-64 into my_SI
	| apply my_SI
	|fields _time Expenses predicted* upper* lower*

![](image./SI.png)
